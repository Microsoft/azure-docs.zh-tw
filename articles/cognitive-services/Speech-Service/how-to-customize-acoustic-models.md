---
title: 使用語音服務建立原音模型 - Azure 認知服務
description: 了解如何在 Azure 認知服務中使用語音服務建立原音模型。
services: cognitive-services
author: PanosPeriorellis
ms.service: cognitive-services
ms.component: speech-service
ms.topic: tutorial
ms.date: 06/25/2018
ms.author: panosper
ms.openlocfilehash: 39e591f6154573bb25fccc423ff63a82f282beaf
ms.sourcegitcommit: 7bc4a872c170e3416052c87287391bc7adbf84ff
ms.translationtype: HT
ms.contentlocale: zh-TW
ms.lasthandoff: 10/02/2018
ms.locfileid: "48017345"
---
# <a name="tutorial-create-a-custom-acoustic-model"></a>教學課程：建立自訂原音模型

如果您的應用程式專用於有特殊錄音裝置或條件的特定環境 (例如汽車)，或由特定使用者族群使用，那麼建立自訂原音模型就相當實用。 例如，帶有口音的語音、特定背景雜音或使用特定麥克風來錄音。

在本文中，您將了解：
> [!div class="checklist"]
> * 準備資料
> * 匯入原音資料集
> * 建立自訂原音模型

如果您沒有 Azure 認知服務帳戶，請在開始前建立[免費帳戶](https://azure.microsoft.com/try/cognitive-services)。

## <a name="prerequisites"></a>必要條件

開啟[認知服務訂用帳戶](https://cris.ai/Subscriptions)頁面，確任您的認知服務帳戶已連線到訂用帳戶。

您可以選取 [與現有訂用帳戶連線]，連線到 Azure 入口網站中建立的語音服務訂用帳戶。

如需在 Azure 入口網站中建立語音服務訂用帳戶的相關資訊，請參閱[免費試用語音服務](get-started.md)。

## <a name="prepare-the-data"></a>準備資料

若要針對特殊網域自訂原音模型，您必須有語音資料集合。 這個集合的範圍可以是幾個語句到數百個小時的語音內容。 集合包含一組語音資料的音訊檔，以及各音訊檔文字記錄的文字檔。 音訊資料要能代表您想要使用辨識器的案例。

例如︰

* 如果您想要更清楚地辨識吵雜工廠環境中的語音，音訊檔內就應該包含人們在吵雜工廠中說話的聲音。
* 如果您想要讓單一演講者的表現發揮最佳效果，例如，您想要抄寫美國總統富蘭克林‧羅斯福的所有「爐邊談話」，則音訊檔內就應該包含許多只有該名演講者的範例。

用來自訂原音模型的原音資料集是由兩個部分所組成：(1) 一組包含語音資料的音訊檔和 (2) 包含所有音訊檔文字記錄的檔案。

### <a name="audio-data-recommendations"></a>音訊資料建議

* 資料集中的所有音訊檔應儲存為 WAV (RIFF) 音效格式。
* 音訊的取樣率必須為 8 千赫茲 (KHz) 或 16 kHz，範例值應儲存為未壓縮的脈衝碼調制 (PCM) 16 位元帶正負號整數 (短)。
* 僅支援單聲道 (mono) 音訊檔。
* 音訊檔的長度必須介於 100 毫秒與 1 分鐘之間。 每個音訊檔的開頭和結尾最好至少有 100 毫秒是無聲的，有時候 500 毫秒至 1 秒間沒聲音都是可行的。
* 如果您的資料中有背景噪音，建議您也對一些資料範例使用較長的無聲區段，例如，在您語音內容前面和/或後面保留幾秒的無聲區段。
* 每個音訊檔應包含單一語句，例如聽寫的單一句子、單一查詢或對話系統的單一回合。
* 資料集中的每個音訊檔應具有唯一檔名，且副檔名應為 .wav。
* 該組音訊檔應放在沒有子目錄的單一資料夾中，而且整組音訊檔應封裝成單一的 zip 檔案封存。

> [!NOTE]
> 目前，可透過入口網站匯入上限為 2 GB 的資料，因此這就是原音資料集的大小上限。 對應到以 16 KHz 錄製的音訊大約是 17 小時，以 8 KHz 錄製的音訊大約是 34 小時。 下表摘要說明音訊資料的主要需求：
>

| 屬性 | 值 |
|---------- |----------|
| 檔案格式 | RIFF (WAV) |
| 取樣率 | 8000 赫茲 (Hz) 或 16000 Hz |
| 聲道 | 1 (mono) |
| 樣本格式 | PCM，16 位元整數 |
| 檔案持續時間 | 0.1 秒 < 持續時間 < 60 秒 |
| 無聲迴圈 | > 0.1 秒 |
| 封存格式 | .zip |
| 封存大小上限 | 2 GB |

> [!NOTE]
> 檔案名稱應該僅使用拉丁字元，並且遵循「檔案名稱.副檔名」的格式

## <a name="language-support"></a>語言支援

如需支援自訂**語音轉換文字**語言模型的語言完整清單，請參閱[語音服務的支援語言](language-support.md#speech-to-text)。

### <a name="transcriptions-for-the-audio-dataset"></a>音訊資料集的文字記錄

所有 WAV 檔案的文字記錄應包含在單一純文字檔案中。 文字記錄檔案的每一行都應包含其中一個音訊檔案的名稱，然後後面接著相對應的文字記錄。 檔案名稱和文字記錄應該以定位字元 (\t) 分隔。

  例如︰
```
  speech01.wav  speech recognition is awesome
  speech02.wav  the quick brown fox jumped all over the place
  speech03.wav  the lazy dog was not amused
```
> [!NOTE]
> 文字記錄應使用 UTF-8 位元組順序標記 (BOM) 編碼。

文字記錄會經過文字正規化，以便系統進行處理。 不過，有一些重要的正規化，必須由使用者在將資料上傳到自訂語音服務_之前_完成。 請參閱[使用語音服務時的文字記錄方針](prepare-transcription.md)，了解準備文字記錄時要使用的適當語言。

使用[語音服務入口網站](https://cris.ai)來執行後續章節中的步驟。

## <a name="import-the-acoustic-dataset"></a>匯入原音資料集

備妥音訊檔和文字記錄之後，即可將這些項目匯入服務 Web 入口網站。

若要匯入它們，請先確定您已登入[語音服務入口網站](https://cris.ai)。 然後，在功能區的 [自訂語音] 下拉式清單中，選取 [調適資料]。 如果這是您第一次將資料上傳到自訂語音服務，會顯示名為「資料集」的空白資料表。 

在 [原音資料集] 資料列中選取 [匯入] 按鈕，網站會顯示上傳新資料集的頁面。

![匯入原音資料頁面](media/stt/speech-acoustic-datasets-import.png)

在 [名稱] 和 [描述] 方塊中，輸入適當的資訊。 易記的描述有助於追蹤您上傳的各種資料集。 

在 [文字記錄檔案 (.txt)] 和 [音訊檔案 (.zip)] 方塊中，選取 [瀏覽]，然後選取純文字的文字記錄檔案和 WAV 檔案的 zip 封存檔。 準備完成時，選取 [匯入] 來上傳您的資料。 您的資料隨即上傳。 對於較大的資料集，匯入程序可能需要幾分鐘的時間。

上傳完成時，返回 [原音資料集] 資料表。 顯示的項目是對應至您原音資料集的項目。 請注意，其已獲派唯一識別碼 (GUID)。 資料會顯示其目前狀態：當資料排入佇列以進行處理時，其狀態會是「未開始」，資料正在通過驗證時會顯示「執行中」，資料可供使用時，則會顯示「完成」。

資料驗證包含一系列檢查，包括驗證音訊檔的檔案格式、長度和取樣率，以及驗證文字記錄檔案的格式及執行某些文字正規化。

當狀態為「成功」時，您可以選取 [詳細資料] 來檢視原音資料驗證報告。 您會看到通過驗證或驗證失敗的語句數目，以及失敗語句的詳細資料。 在下圖的範例中，兩個 WAV 檔案會因為不當的音訊格式，所以無法驗證。 在此資料集中，一個檔案具有不正確的取樣率，另一個檔案則有不正確的檔案格式。

![調適資料詳細資料頁面](media/stt/speech-acoustic-datasets-report.png)

如果您想要變更資料集的名稱或描述，您可以選取 [編輯] 連結並變更這些項目。 您無法修改文字記錄或音訊檔案項目。

## <a name="create-a-custom-acoustic-model"></a>建立自訂原音模型

原音資料集的狀態為「完成」之後，您可以使用資料集來建立自訂原音模型。 若要這麼做，請選取 [自訂語音] 下拉式清單中的 [原音模型]。 標示為 [您的模型] 的資料表會列出您所有自訂原音模型。 如果這是您第一次使用，則此資料表會是空白的。 資料表標題會顯示目前的地區設定。 目前，您只能針對英文 (美國) 來建立原音模型。

若要建立新的模型，請選取資料表標題下方的 [新建]。 同樣地，輸入名稱和描述，以便識別此模型。 例如，您可以使用 [描述] 欄位來記錄建立模型時所用的起始模型和原音資料集。 

接下來，在 [基底原音模型] 下拉式清單中，選取基底模型。 基底模型是自訂的起點。 有兩種基底原音模型可選擇：
* **Microsoft 搜尋與聽寫 AM** 模型適用於應用程式上的語音導向作業，例如命令、搜尋查詢或聽寫。 
* **Microsoft 交談模型**適用於辨識以交談形式說出的語音。 這類型的語音通常會指向另一個人，並且發生在話務中心或會議中。 

在交談式模型中，部分結果發生延遲的機率會高於搜尋和聽寫模型。

> [!NOTE]
> 我們目前推出新的**通用**模型，目標是要能處理所有案例。 上述模型仍會公開給大眾使用。

接下來，在 [原音資料] 下拉式清單中，選取您想要用來執行自訂的原音資料。

![建立原音模型頁面](media/stt/speech-acoustic-models-create2.png)

當處理完成時，您可以選擇是否對新模型執行精確度測試。 這個測試會對使用自訂原音模型的指定原音資料集執行語音轉文字評估，然後報告結果。 若要執行這項測試，請選取 [精確度測試] 核取方塊。 然後，在下拉式清單中選取語言模型。 如果您尚未建立任何自訂語言模型，下拉式清單中只會顯示基底語言模型。 若要選取最適當的語言模型，請參閱[教學課程：建立自訂語言模型](how-to-customize-language-model.md)。

最後，選取您想要用來評估自訂模型的原音資料集。 如果您執行精確度測試是為了真正了解模型的效能，選取的原音資料集務必與用來建立模型的資料集不同，這一點相當重要。 您無法藉由訓練資料的精確度測試，評估調整後的模型在實際情況下會如何執行。 結果會過於樂觀。 也請注意，精確度測試僅限 1000 個語句。 如果用於測試的原音資料集太大時，將只會評估前 1000 個語句。

當您準備好要開始執行自訂程序時，請按 [建立]。

原音模型資料表會顯示與這個新模型對應的新項目。 資料表也會顯示程序的狀態：「等候」、「處理中」或「完成」。

![原音模型頁面](media/stt/speech-acoustic-models-creating.png)

## <a name="next-steps"></a>後續步驟

- [取得您的語音服務試用訂用帳戶](https://azure.microsoft.com/try/cognitive-services/)
- [以 C# 辨識語音](quickstart-csharp-dotnet-windows.md)
- [Git 範例資料](https://github.com/Microsoft/Cognitive-Custom-Speech-Service)
