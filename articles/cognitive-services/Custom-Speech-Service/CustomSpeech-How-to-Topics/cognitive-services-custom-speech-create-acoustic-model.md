---
title: 使用自訂語音服務建立原音模型的教學課程 - Microsoft 認知服務 | Microsoft Docs
description: 在本教學課程中，您將了解如何使用 Microsoft 認知服務中的自訂語音服務來建立原音模型。
services: cognitive-services
author: PanosPeriorellis
manager: onano
ms.service: cognitive-services
ms.component: custom-speech
ms.topic: tutorial
ms.date: 05/03/2017
ms.author: panosper
ms.openlocfilehash: 53e93a08782ba66e69b903c32c4c3c7417e5a801
ms.sourcegitcommit: 1aacea6bf8e31128c6d489fa6e614856cf89af19
ms.translationtype: HT
ms.contentlocale: zh-TW
ms.lasthandoff: 10/16/2018
ms.locfileid: "49344569"
---
# <a name="tutorial-create-a-custom-acoustic-model"></a>教學課程：建立自訂原音模型

[!INCLUDE [Deprecation note](../../../../includes/cognitive-services-custom-speech-deprecation-note.md)]

在本教學課程中，您將針對要讓應用程式辨識的語音資料建立自訂原音模型。 如果您的應用程式專用於特定環境 (例如吵雜的工廠)，或由特定使用者族群使用，那麼建立自訂原音模型就相當實用。

在本教學課程中，您了解如何：
> [!div class="checklist"]
> * 準備資料
> * 匯入原音資料集
> * 建立自訂原音模型

如果您沒有認知服務帳戶，請在開始前建立[免費帳戶](https://cris.ai)。

## <a name="prerequisites"></a>必要條件

開啟[認知服務訂用帳戶](https://cris.ai/Subscriptions)頁面，確任您的認知服務帳戶已連線到訂用帳戶。

如果沒有列出任何訂用帳戶，您可以按一下 [取得免費訂用帳戶] 按鈕，讓認知服務為您建立帳戶。 或是，您可以按一下 [與現有訂用帳戶連線] 按鈕，連線到 Azure 入口網站中建立的自訂搜尋服務訂用帳戶。

如需在 Azure 入口網站中建立自訂搜尋服務訂用帳戶的資訊，請參閱[在 Azure 入口網站中建立認知服務 API 帳戶](../../cognitive-services-apis-create-account.md)。

## <a name="prepare-the-data"></a>準備資料

若要針對特殊網域自訂原音模型，您必須有語音資料集合。 此集合包含一組語音資料的音訊檔，以及各音訊檔文字記錄的文字檔。 音訊資料要能代表您想要使用辨識器的案例。

例如︰

*   如果您想要更清楚地辨識吵雜工廠環境中的語音，音訊檔內就應該包含人們在吵雜工廠中說話的聲音。
<a name="Preparing data to customize the acoustic model"></a>
*   如果您想要讓單一演講者的表現發揮最佳效果，例如，您想要抄寫美國總統富蘭克林‧羅斯福的所有「爐邊談話」，則音訊檔內就應該包含許多只有該名演講者的範例。

用來自訂原音模型的原音資料集是由兩個部分所組成：(1) 一組包含語音資料的音訊檔和 (2) 包含所有音訊檔文字記錄的檔案。

### <a name="audio-data-recommendations"></a>音訊資料建議

*   資料集中的所有音訊檔應儲存為 WAV (RIFF) 音效格式。
*   音訊的取樣率必須為 8 kHz 或 16 kHz，範例值應儲存為未壓縮的 PCM 16 位元帶正負號整數 (短)。
*   僅支援單聲道 (mono) 音訊檔。
*   音訊檔的長度必須介於 100 毫秒與 1 分鐘之間。 每個音訊檔的開頭和結尾最好至少有 100 毫秒是無聲的，有時候 500 毫秒至 1 秒間沒聲音都是可行的。
*   如果您的資料中有背景噪音，建議您也對一些資料範例使用較長的無聲區段，例如，在您語音內容前面和/或後面保留幾秒的無聲區段。
*   每個音訊檔應包含單一語句，例如聽寫的單一句子、單一查詢或對話系統的單一回合。
*   資料集中的每個音訊檔應具有唯一檔名，且副檔名應為 "wav"。
*   該組音訊檔應放在沒有子目錄的單一資料夾中，而且整組音訊檔應封裝成單一的 ZIP 檔案封存。

> [!NOTE]
> 目前，可透過入口網站匯入上限為 2 GB 的資料，因此這就是原音資料集的大小上限。 對應到以 16 kHz 錄製的音訊大約是 17 小時，以 8 kHz 錄製的音訊大約是 34 小時。 下表摘要說明音訊資料的主要需求。
>

| 屬性 | 值 |
|---------- |----------|
| 檔案格式 | RIFF (WAV) |
| 取樣率 | 8000 Hz 或 16000 Hz |
| 聲道 | 1 (mono) |
| 樣本格式 | PCM，16 位元整數 |
| 檔案持續時間 | 0.1 秒 < 持續時間 < 60 秒 |
| 無聲迴圈 | > 0.1 秒 |
| 封存格式 | ZIP |
| 封存大小上限 | 2 GB |

### <a name="transcriptions"></a>文字記錄

所有 WAV 檔案的文字記錄應包含在單一純文字檔案中。 文字記錄檔案的每一行都應具有其中一個音訊檔案的名稱，然後後面接著相對應的文字記錄。 檔案名稱和文字記錄應該以定位字元 (\t) 分隔。

  例如︰
```
  speech01.wav  speech recognition is awesome

  speech02.wav  the quick brown fox jumped all over the place

  speech03.wav  the lazy dog was not amused
```

文字記錄會經過文字正規化，以便系統進行處理。 不過，有一些重要的正規化，必須由使用者在將資料上傳到自訂語音服務_之前_完成。 準備您的文字記錄時，請針對適當語言參閱[文字記錄指導方針](cognitive-services-custom-speech-transcription-guidelines.md)上的區段。

使用[自訂語音服務入口網站](https://cris.ai)完成下列步驟。 

## <a name="import-the-acoustic-data-set"></a>匯入原音資料集

一旦備妥音訊檔和文字記錄後，即可將這些項目匯入服務入口網站。

若要這樣做，請先確定您已登入[自訂語音服務入口網站](https://cris.ai)。 然後按一下上方功能區的 [自訂語音] 下拉式選單，然後選取 [調整的資料]。 如果這是您第一次將資料上傳到自訂語音服務，您會看到名為「資料集」的空白資料表。 

按一下 [原音資料集] 資料列中的 [匯入] 按鈕，網站會顯示上傳新資料集的頁面。

![嘗試](../../../media/cognitive-services/custom-speech-service/custom-speech-acoustic-datasets-import.png)

在適當的文字方塊中輸入 [名稱] 和 [描述]。 這些資料有助於追蹤您上傳的各種資料集。 接下來，針對「文字記錄檔」和「WAV 檔」按一下 [選擇檔案]，並各別選取純文字的文字記錄檔和 WAV 檔的 ZIP 封存。 完成這些動作後，按一下 [匯入] 來上傳您的資料。 您的資料會隨即上傳。 對於較大型的資料集，這可能需要幾分鐘的時間。

上傳完成時，您會返回「原音資料集」資料表，並且會看到您原音資料集的對應項目。 請注意，其已獲派唯一識別碼 (GUID)。 資料也會有狀態來反映其目前的狀態。 當資料排入佇列以進行處理時，其狀態會是「等待中」，資料正在通過驗證時會顯示「處理中」，資料可供使用時，則會顯示「完成」。

資料驗證包含一系列檢查，包括驗證音訊檔的檔案格式、長度和取樣率，以及驗證文字記錄檔案的格式及執行某些文字正規化。

當狀態為「完成」時，您可以按一下 [詳細資料] 來查看原音資料驗證報告。 您會看到通過驗證或驗證失敗的語句數目，以及失敗語句的詳細資料。 在下列範例中，兩個 WAV 檔案因為音訊格式不正確而驗證失敗 (在此資料集中，一個取樣率不正確，另一個檔案格式不正確)。

![嘗試](../../../media/cognitive-services/custom-speech-service/custom-speech-acoustic-datasets-report.png)

在某些時候，如果您想要變更資料集的名稱或描述，您可以按一下 [編輯] 連結並變更這些項目。 請注意，您無法修改音訊檔或文字記錄。

## <a name="create-a-custom-acoustic-model"></a>建立自訂原音模型

當原音資料集的狀態為「完成」時，即可用來建立自訂原音模型。 若要這麼做，請按一下 [自訂語音] 下拉式功能表中的 [原音模型]。 您會看到名為「您的模型」的資料表，其中會列出您所有的自訂原音模型。 如果您是第一次使用，此資料表會是空白的。 目前的地區設定會顯示在資料表標題。 目前，原音模型只能針對英文 (美國) 來建立。

若要建立新的模型，按一下資料表標題下方的 [新建]。 同樣地，輸入名稱和描述，以便識別此模型。 例如，[描述] 欄位可用來記錄建立模型時所用的起始模型和原音資料集。 下一步，從下拉式功能表中選取 [基底原音模型]。 基底模型是作為自訂起始點的模型。 有兩種基底原音模型可選擇。 _Microsoft 搜尋與聽寫 AM_ 適用於應用程式上的語音導向作業，例如命令、搜尋查詢或聽寫。 _Microsoft 交談模型_適用於辨識以交談形式說出的語音。 這類型的語音通常會指向另一個人，並且發生在話務中心或會議中。 請注意，在交談式模型中，部分結果發生延遲的機率會高於搜尋和聽寫模型。

接下來，使用下拉式功能表選取要用來執行自訂的原音資料。

![嘗試](../../../media/cognitive-services/custom-speech-service/custom-speech-acoustic-models-create2.png)

您可以選擇是否在處理完成時，對新模型執行離線測試。 這將會對使用自訂原音模型的指定原音資料集執行語音轉文字評估，並且報告結果。 若要執行這項測試，請選取 [精確度測試] 核取方塊。 從下拉式功能表中選取語言模型。 如果您尚未建立任何自訂語言模型，下拉式清單中只會有基底語言模型。 請參閱指南中基底語言模型的[描述](cognitive-services-custom-speech-create-language-model.md)，並選取最合適的模型。

最後，選取您想要用來評估自訂模型的原音資料集。 如果您執行精確度測試，選取的原音資料集務必與用來建立模型的資料集不同，如此才能真正了解模型的效能。 也請注意，離線測試僅限 1000 個語句。 如果用於測試的原音資料集大於此限制時，將只會評估前 1000 個語句。

當您準備好要開始執行自訂程序時，請按 [建立]。

現在，您會在原音模型資料表中看到與此新模型對應的新項目。 程序的狀態會反映在資料表中。 這些狀態為「等候中」、「處理中」和「完成」。

![嘗試](../../../media/cognitive-services/custom-speech-service/custom-speech-acoustic-models-creating.png)

## <a name="next-steps"></a>後續步驟

在本教學課程中，您已開發自訂的原音模型來搭配使用音訊檔和文字記錄。 若要建立自訂語言檔案來搭配使用文字檔案，請繼續建立自訂語言模型的教學課程。

> [!div class="nextstepaction"]
> [建立自訂語言模型](cognitive-services-custom-speech-create-language-model.md)
